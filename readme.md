# Automatisierte Aktienanalyse nach Peter Lynch (Praxisprojekt)

---

## Inhaltsverzeichnis
- [1. Einleitung](#1-einleitung)
- [2. Bezug zum WI-Projekt](#2-bezug-zum-wi-projekt)
- [3. Theoretische Grundlage â€“ KurzÃ¼berblick](#3-theoretische-grundlage--kurzÃ¼berblick)
- [4. Systemarchitektur](#4-systemarchitektur)
- [5. Datenquellen und API-Abruf](#5-datenquellen-und-api-abruf)
- [6. Datenmodell und Elasticsearch-Mapping](#6-datenmodell-und-elasticsearch-mapping)
- [7. Streamlit-Dashboard](#7-streamlit-dashboard)
- [8. Setup & Deployment](#8-setup--deployment)
- [9. Fazit](#10-fazit)
- [10. Quellen](#11-quellen)

---

## 1. Einleitung

### 1.1 Motivation  
Ã–ffentlich verfÃ¼gbare Finanzdaten werden hÃ¤ufig nur manuell ausgewertet oder in unstrukturierten Formaten bereitgestellt.  
Dieses Praxisprojekt verfolgt das Ziel, fundamentale Unternehmensdaten automatisiert zu verarbeiten, zentral zu speichern und anhand eines strukturierten Bewertungsmodells â€“ basierend auf der Investmentstrategie von Peter Lynch â€“ visuell analysierbar zu machen.

### 1.2 Projektziel  
Ziel ist der Aufbau einer durchgÃ¤ngigen Datenpipeline, die:

1. Kennzahlen zu allen Aktien die mal einer der S&P-500-Aktien sind/wahren automatisiert Ã¼ber APIs abruft  
2. Sie in Elasticsearch strukturiert speichert  
3. Sie anhand der 6 Lynch-Kategorien klassifiziert  
4. Ãœber ein Streamlit-Dashboard filter-, vergleich- und visualisierbar macht  
5. Grundlage fÃ¼r tÃ¤gliche Updates, Alerts, Backtesting und ML-Erweiterungen bildet  


### 1.3 Herangehensweise

Das Projekt wurde iterativ umgesetzt und folgt einer klaren Data-Pipeline-Struktur:

1. **Definition der Anforderungen**  
   Die theoretischen Lynch-Kriterien wurden analysiert, in konkrete Kennzahlen Ã¼bersetzt und als Regelwerk fÃ¼r die spÃ¤tere Klassifikation festgelegt.

2. **Auswahl & Test der Datenquellen**  
   Drei APIs (FMP, yfinance, Alpha Vantage) wurden hinsichtlich DatenqualitÃ¤t, Abdeckung und Historie geprÃ¼ft und kombiniert.

3. **Entwicklung der ETL-Pipeline**  
   Eine modulare Python-Pipeline extrahiert alle S&P-500-Daten, vereinheitlicht sie und speichert sie historisiert in Elasticsearch.

4. **Aufbau des Datenmodells**  
   Ein einheitliches Elasticsearch-Mapping sorgt dafÃ¼r, dass alle Kennzahlen strukturiert, vergleichbar und performant abfragbar sind.

5. **Automatische Lynch-Klassifikation**  
   Die Regeln wurden programmatisch umgesetzt, sodass jede Aktie automatisch kategorisiert und bewertet werden kann.

6. **Entwicklung des Streamlit-Dashboards**  
   Drei Pages (Dashboard, Top-10, Portfolio) visualisieren die Daten, ermÃ¶glichen Screening, Vergleiche und Portfolio-Aufbau.

â¡ï¸ Ergebnis: Ein durchgÃ¤ngiger Analyse-Workflow von der Datenbeschaffung bis zur Bewertung und Visualisierung â€“ modular, automatisierbar und erweiterbar.



## 2. Bezug zum WI-Projekt

Dieses Praxisprojekt baut auf dem vorherigen WI-Projekt auf, in dem die **theoretische Grundlage** zu Peter Lynch (Broker) detailliert dokumentiert wurde (inkl. Kennzahlen, Zielwerte, Quellen und API-Endpunkte).

| WI-Projekt (Theorie) | Praxisprojekt (Technik) |
|----------------------|--------------------------|
| Lynch-Kategorien erklÃ¤rt | Kategorien werden automatisch berechnet |
| Tabellen mit Kennzahlen | API-Daten werden geladen & gespeichert |
| Zielwerte definiert | Bewertung erfolgt algorithmisch |
| Dokumentation in Textform | Analyse & UI Ã¼ber Dashboard |

â¡ï¸ VollstÃ¤ndige Theorie befindet sich in der WI-Projektdokumentation.  
â¡ï¸ Diese README enthÃ¤lt **nur eine kompakte Zusammenfassung**.

---


## 3. Theoretische Grundlage â€“ KurzÃ¼berblick

| Kategorie     | Typische Unternehmen             | Kerneigenschaft                         | Kurzbeschreibung (nach Peter Lynch) |
|---------------|----------------------------------|------------------------------------------|-------------------------------------|
| Slow Growers  | Versorger, alte Industrien       | Niedriges Wachstum, stabile Dividenden   | GroÃŸe, etablierte Firmen mit kaum Wachstum; Lynch nutzt sie hauptsÃ¤chlich wegen ihrer Dividenden. |
| Stalwarts     | Markenriesen (z. B. Coca-Cola)   | 5â€“10 % Gewinnwachstum                    | Solide Unternehmen mit stabilem Wachstum; Lynch sieht sie als â€sichere Pferdeâ€œ im Portfolio. |
| Fast Growers  | Wachstumsunternehmen             | > 20 % Gewinnwachstum                    | Kleine bis mittelgroÃŸe Firmen mit hohem Wachstum; laut Lynch die besten Chancen auf groÃŸe Kursgewinne. |
| Cyclicals     | Auto, Stahl, Airlines            | Schwanken mit Konjunktur                 | Unternehmen, die stark von wirtschaftlichen Zyklen abhÃ¤ngen; Timing ist entscheidend. |
| Turnarounds   | Sanierungskandidaten             | RÃ¼ckkehr zur ProfitabilitÃ¤t              | Unternehmen in schwieriger Lage, die sich erholen kÃ¶nnen; hohe Chance, aber auch hÃ¶heres Risiko. |
| Asset Plays   | Versteckte Werte                 | Buchwert > Marktwert                     | Firmen, deren wahre Werte (Immobilien, VermÃ¶gen, Beteiligungen) vom Markt unterschÃ¤tzt werden. |
---
Nur die technische Umsetzung erfolgt hier.  
Die vollstÃ¤ndige Theorie â†’ siehe WI-Projekt.

## 4. Systemarchitektur

### 4.1 ArchitekturÃ¼bersicht
#### 4.1.1. Development Environment (DEV)
Lokale Umgebung zum Entwickeln und Testen:

- Python **3.10+**
- Docker Compose
- Elasticsearch (lokaler Container)
- Streamlit (lokal auf **Port 8501**)
- Lokale `.env`-Datei mit API-Keys

Diese Umgebung wird wÃ¤hrend der Entwicklung genutzt, um ETL-Pipelines, Mapping, Dashboard und API-Anbindungen zu testen.

---

#### 4.1.2. Runtime Environment (Execution Layer)
Betriebsumgebung der ETL-Pipeline:

- Python-Skripte (`load_sp500.py`, `ingest_fmp.py`, etc.)
- Cron/Scheduler fÃ¼r automatische tÃ¤gliche Updates (geplant)
- Zugriff auf externe APIs (FMP, yfinance, Alpha Vantage)
- Verbindung zu Elasticsearch (lokal oder remote)

Dieses Environment fÃ¼hrt alle automatisierten Datenlade- und Transformationsprozesse aus.

---

#### 4.1.3. Container Environment / Infrastruktur
Definiert Ã¼ber `docker-compose.yml`:

- Container fÃ¼r Elasticsearch, Dashboard und optionale ETL-Services
- Netzwerkdefinition, Ports, Volumes
- Elasticsearch-Cluster-Konfiguration (Index, Storage, Persistenz)
- Isolierte Services fÃ¼r saubere Trennung der Komponenten

Dieses Environment stellt die technische Infrastruktur bereit, in der alle Services ausgefÃ¼hrt werden.

---

#### 4.1.4. Web-Environment (Dashboard)
Frontend-Umgebung fÃ¼r die BenutzeroberflÃ¤che:

- Streamlit-Dashboard
- Live-Abfragen gegen Elasticsearch
- Visualisierung von Kennzahlen, Zeitreihen, Rankings und Portfolios

Dieses Environment bildet die interaktive Analyseschicht des Projekts.



### 4.2 Architekturdiagramm

            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  Datenquellen (APIs)       â”‚
            â”‚  FMP / yfinance / AV       â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ JSON-Response
                         â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚  Python ETL  â”‚
                â”‚ (load_data)  â”‚
                â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ transformed data
                       â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   Elasticsearch Index  â”‚
            â”‚   (stocks, metrics)    â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚ query
                      â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   Streamlit Dashboard  â”‚
            â”‚   Charts, Filter, UI   â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Das Architekturdiagramm zeigt den vollstÃ¤ndigen Datenfluss der Anwendung: Finanzdaten werden Ã¼ber mehrere APIs abgerufen und anschlieÃŸend durch eine Python-ETL-Pipeline bereinigt und vereinheitlicht. Die transformierten Daten werden in einem Elasticsearch-Index gespeichert, von dem aus das Streamlit-Dashboard die Informationen abruft, visualisiert und fÃ¼r die Analyse bereitstellt.

---

## 4.3 Page Diagramme

<details style="font-size: 1.1rem; margin-bottom: 10px;">
  <summary>ğŸ“Š <strong>Dashboard</strong></summary>
  <br>
  <img src="data/Dashboard.png" alt="Dashboard" width="800">
</details>
Die Dashboard-Seite dient der Einzelanalyse einer Aktie. Nach Eingabe eines Symbols werden alle verfÃ¼gbaren Kennzahlen geladen, berechnet und visualisiert. ZusÃ¤tzlich erfolgt automatisch die Peter-Lynch-Kategorisierung inklusive BegrÃ¼ndung. Historische Zeitreihen (z. B. KGV, Wachstum, FCF) ermÃ¶glichen eine detaillierte Bewertung der Unternehmensentwicklung.

<details style="font-size: 1.1rem; margin-bottom: 10px;">
  <summary>ğŸ“ˆ <strong>Portfolio</strong></summary>
  <br>
  <img src="data/Portfolio.png" alt="Portfolio" width="800">
</details>
Die Portfolio-Seite ermÃ¶glicht den Aufbau eines eigenen Wertpapierportfolios basierend auf den Lynch-Kategorien. Nutzer kÃ¶nnen Aktien auswÃ¤hlen, Gewichte festlegen und unterschiedliche Strategien (z. B. defensiv, wachstumsorientiert) vergleichen. Zudem werden Soll- und Ist-Verteilungen visualisiert und in Elasticsearch gespeichert.

<details style="font-size: 1.1rem; margin-bottom: 10px;">
  <summary>ğŸ“‰ <strong>Top 10</strong></summary>
  <br>
  <img src="data/Top_10.png" alt="Top 10" width="800">
</details>
Die Top-10-Seite dient als Screening- und Ranking-Tool. Alle Aktien werden anhand der gewÃ¤hlten Lynch-Kategorie automatisch bewertet und nach Score sortiert. Branchen- und Marktkapitalisierungsfilter ermÃ¶glichen eine gezielte Auswahl. Zu jeder Aktie wird angezeigt, welche Kriterien erfÃ¼llt wurden und wie der Score zustande kommt.
---

## 5. Datenquellen & API-Abruf

Dieser Abschnitt beschreibt, **woher** die Daten stammen und **wie** sie technisch in das System geladen werden â€“ noch ohne Bezug auf das Elasticsearch-Datenmodell.

| Quelle | Skript | Typische Felder (roh) | API-Endpunkt / Methode |
|--------|--------|------------------------|------------------------|
| FMP (FinancialModelingPrep) | `ingest_fmp.py` | `peRatio`, `priceToBook`, `marketCap`, `dividendYield` | `/api/v3/quote/{symbol}` |
| yfinance | `ingest_yf.py` | `trailingPE`, `freeCashFlow`, `beta`, `sharesOutstanding` | `Ticker.info`, `balance_sheet`, `cashflow` |
| Alpha Vantage | `Ingest_AV.py` | EPS-Historie, SG&A-Daten | `EARNINGS`, `INCOME_STATEMENT` |
| FMP JSON-Batch (offline) | `ingest_fmp_sp.py` | kompletter Fundamentaldatenblock | lokale JSON-Dateien |

â¡ï¸ In diesem Abschnitt keine Feldtypen, kein Mapping, keine Normalisierung.

### 5.2 Beispiel-Response (FMP)

    {
    "symbol": "AAPL",
    "peRatioTTM": 28.31,
    "revenuePerShareTTM": 24.52,
    "dividendYieldTTM": 0.0059
    }

## 6. Datenmodell und Elasticsearch-Mapping
    Dieser Abschnitt beschreibt, wie die eingehenden Daten anschlieÃŸend strukturiert und vereinheitlicht im Elasticsearch-Index gespeichert werden.  
    Indexname: stocks   
    Dokument-ID: SYMBOL |YYYY-MM-DD|  (z. B. AAPL|2025-11-06)

### 6.1 Einheitliche Zielfelder im Index
| Zielfeld         | Typ     | Herkunft / Fallback                      |
| ---------------- | ------- | ---------------------------------------- |
| `peRatio`        | double  | FMP.peRatio â†’ yfinance.trailingPE        |
| `earningsGrowth` | double  | berechnet aus Historie                   |
| `revenueGrowth`  | double  | YoY Ableitung                            |
| `debtToAssets`   | double  | totalDebt / totalAssets                  |
| `fcfMargin`      | double  | freeCashFlow / revenue                   |
| `sgaTrend`       | boolean | berechnet aus SG&A-Quote (Alpha Vantage) |
..


### 6.2  Beispiel-Mapping (JSON)
    {
    "mappings": {
        "properties": {
        "symbol":       {"type": "keyword"},
        "date":         {"type": "date"},
        "source":       {"type": "keyword"},
        "ingested_at":  {"type": "date"},

        "peRatio":      {"type": "double"},
        "priceToBook":  {"type": "double"},
        "dividendYield":{"type": "double"},
  
        ..
    }
    }
    }
### 6.3 Beispiel-Dokument in Elasticsearch

    {
    "_id": "AAPL|2025-11-06",
    "_source": {
        "symbol": "AAPL",
        "date": "2025-11-06",
        "source": "FMP",
        "ingested_at": "2025-11-06T12:34:56Z",

        "peRatio": 28.3,
        "priceToBook": 39.2,
        "dividendYield": 0.0059,
        "marketCap": 2.9e12,

        "earningsGrowth": 0.12,
        "revenueGrowth": 0.08,
        "fcfMargin": 0.24,
        "debtToAssets": 0.31,
        "beta": 1.18,
        "sgaTrend": true
    }
    }



â¡ï¸ Ab hier sind die Daten bereit fÃ¼r Klassifikation, Score & Dashboard.

## 7. Streamlit-Dashboard

Das Streamlit-Dashboard besteht aus drei Pages, die gemeinsam die Analyse-, Screening- und Portfolio-Funktionen bereitstellen.  
Alle Daten werden live aus Elasticsearch geladen und basieren auf den zuvor ingestierten API-Daten (FMP, yfinance, Alpha Vantage).

### 7.1 Funktionen

- **Dashboard (Einzelanalyse):**  
  - Suche nach Ticker  
  - KPI-Panel (KGV, EPS, FCF, Div. Yield, Debt/Equity etc.)  
  - Automatische Peter-Lynch-Kategorisierung inkl. BegrÃ¼ndung  
  - Interaktive Zeitreihen-Charts (KGV, Wachstum, P/B, FCF etc.)  
  - Glossar & KPI-ErklÃ¤rungen  
  [Link zur Dashboard-Page](http://localhost:8501/Dashboard)

- **Top-10 (Screening & Ranking):**  
  - Ranking je Peter-Lynch-Kategorie (z. B. â€Fast Growersâ€œ, â€Stalwartsâ€œ)  
  - Branchen- & Marktkapitalisierungs-Filter  
  - Scoring-Logik mit Trefferquote pro Kriterium  
  - Detailansicht pro Aktie: â€Kriterium erfÃ¼llt / nicht erfÃ¼lltâ€œ   
    [Link zur Top-10 Page](http://localhost:8501/Top_10) 

- **Portfolio (Builder & Verwaltung):**  
  - Auswahl & Gewichtung von Aktien je Kategorie  
  - Strategie-Presets (z. B. defensiv, wachstumsorientiert etc.)  
  - Vergleich Soll- vs. Ist-Gewichtung (inkl. Diagramm)  
  - Speicherung & Laden von Portfolios in Elasticsearch  
    [Link zur Portfolio-Page](https://mein-dashboard.de/Portfolio)

---


### 7.2 Ranking-Logik (Scoring nach Peter Lynch)

Die Bewertung einer Aktie erfolgt anhand eines regelbasierten Scoring-Systems, das pro Lynch-Kategorie unterschiedliche Kennzahlen prÃ¼ft.  
Die Regeln sind zentral in `lynch_criteria.py` definiert und legen fest:

- **welche Kennzahlen relevant sind** (z. B. KGV, EPS-Wachstum, Schuldenquote)
- **ob ein Kriterium verpflichtend oder optional ist**
- **welcher Zielbereich als â€gutâ€œ gilt** (z. B. KGV < 15)

#### Beispiel: Kategorie â€Fast Growerâ€œ

| Kriterium | Zielwert | Pflicht? |
|-----------|----------|----------|
| EPS-Wachstum 5y > 20 % | âœ… | ja |
| Umsatzwachstum > 10 % | âœ… | ja |
| KGV < 35 | âœ… | optional |
| Verschuldung < 50 % | âœ… | optional |
..
#### Berechnung des Scores
1. Jede Aktie wird mit allen Kriterien der gewÃ¤hlten Kategorie verglichen  
2. ErfÃ¼llte Pflicht-Kriterien â†’ **+1 Punkt**  
3. ErfÃ¼llte optionale Kriterien  â†’ **+1 Punkte**  
4. Score = erreichte Punkte / maximal mÃ¶gliche Punkte  
5. Bei gleichem Score erfolgt die SekundÃ¤rsortierung automatisch nach Marktkapitalisierung (absteigend), um grÃ¶ÃŸere und damit tendenziell stabilere Unternehmen zu bevorzugen, denn sie sind stabiler am Markt.   
[Link zur Quelle, die Punkt 5 befÃ¼rwortet.](https://www.sciencedirect.com/science/article/pii/S1094202524000437)

### Beispiel:
![alt text](data/image.png)


## 8. Setup & Deployment

### 8.1 Voraussetzungen
- Docker & Docker Compose  
- Python **3.10+**  
- API-Keys in einer `.env`-Datei

    Beispiel `.env`:
    ```env
    FMP_API_KEY=dein_fmp_key
    ALPHA_VANTAGE_KEY=dein_alpha_vantage_key
    ELASTICSEARCH_URL=http://localhost:9200

    8.2 Startreihenfolge
    Container starten
    docker compose up -d
    Daten laden (S&P 500)
    python load_sp500.py
    Dashboard starten
    streamlit run dashboard.py
    Tipp: PrÃ¼fe http://localhost:8501 (Streamlit) und http://localhost:9200 (Elasticsearch).

---


## 9. Fazit
### ProjektÃ¼bersicht: Automatisierter Analyse-Workflow 

Das Projekt zeigt, dass sich ein vollstÃ¤ndiger, automatisierter Analyse-Workflow fÃ¼r Fundamentaldaten mit vertretbarem Aufwand realisieren lÃ¤sst:

### Kernfunktionen
- **Automatisierte Datenerfassung** Ã¼ber mehrere APIs (FMP, yfinance, Alpha Vantage)  
- **Zentrale & strukturierte Speicherung** in Elasticsearch  
- **Regelbasiertes Bewertungssystem nach Peter Lynch** (inkl. Scoring & Ranking)  
- **Interaktives Streamlit-Dashboard** fÃ¼r Analyse, Screening & Portfolio-Management  

###  Demonstrierter Mehrwert
- API-gestÃ¼tztes **Data Engineering**
- Nutzung einer **Suchindex-Datenbank statt klassischer SQL-Modelle**
- **Nachvollziehbares Regelwerk** statt Blackbox-ML
- **Modulare, wiederverwendbare ETL-Pipelines**
- **Automatisierte Workflows** als Grundlage fÃ¼r spÃ¤tere Skalierung

###  Erweiterbarkeit (bewusst vorgesehen)
- **Technisch**: zusÃ¤tzliche Datenquellen, Backtesting, Alerts, Scheduling
- **Funktional**: ML-Modelle, internationale MÃ¤rkte, Portfolio-Tracking, weitere Bewertungsmodelle
### Zielerreichung

1. **Automatisierter API-Abruf der S&P-500-Daten**  
   Die ETL-Pipeline lÃ¤dt Kennzahlen aus mehreren Quellen (FMP, yfinance, Alpha Vantage) automatisiert und robust.

2. **Strukturierte Speicherung in Elasticsearch**  
   Alle Daten werden vereinheitlicht, historisiert und in einem eigenen Index gespeichert â€“ inklusive Mapping und Typisierung.

3. **Automatische Klassifikation nach den 6 Lynch-Kategorien**  
   Die Bewertungslogik wurde regelbasiert implementiert und arbeitet reproduzierbar sowie transparent.

4. **Visualisierung Ã¼ber ein Streamlit-Dashboard**  
   Die drei entwickelten Pages (Dashboard, Top-10, Portfolio) ermÃ¶glichen Analyse, Screening und Vergleich auf Basis der gespeicherten Daten.

5. **Grundlage fÃ¼r zukÃ¼nftige Erweiterungen geschaffen**  
   Das System ist modular aufgebaut und technisch darauf ausgelegt, spÃ¤ter um tÃ¤gliche Updates, Alerts, Backtesting und ML-Komponenten ergÃ¤nzt zu werden.

---
### Kurzfassung
Aus einem **theoretischen Bewertungsmodell** wurde ein **lauffÃ¤higes, erweiterbares Analyse-System**,  
das echte Investmententscheidungen unterstÃ¼tzen kann.
  
## 10. Quellen
Merger... von Jackie M.L. Chan: https://www.sciencedirect.com/science/article/pii/S1094202524000437  
One Up on Wall Street: https://www.thalia.de/shop/home/artikeldetails/A1003289250  
FMP: https://site.financialmodelingprep.com/developer/docs   
Alpha Vantage: https://www.alphavantage.co/documentation/  
yfinance :   https://pypi.org/project/yfinance/   
Elasticsearch: https://www.elastic.co/de/elasticsearch  
Docker: https://www.docker.com   
Streamlit: https://streamlit.io  
Python: https://www.python.org   
Visualstudio: https://code.visualstudio.com
---


